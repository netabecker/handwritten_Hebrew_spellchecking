{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIBiSiesJ7zM",
        "outputId": "2c0b2384-aaf6-45dc-9ca7-bb0a979d83c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.4.1\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMjX672HG3OK"
      },
      "source": [
        "# Create_augmentations.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaIQ7JcRH5Rq",
        "outputId": "76e664b2-6fb4-4e4d-e419-0a731d967285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------> Example:\n",
            "\n",
            "\n",
            "אחרי שאמות יבואו פתאום אנשים בלי בושה עם חיבוק פולני אחרי שאמות יספרו בחלון בדיחות עתיקות ישפילו פנים אחרי שאמות יגיעו אישית זרים עם זרים ישירו שירים אחרי שאמות בקול חרישי תשטוף הרכילות את הבור הטרי אני אפתח בקבוק עם כמה ממחטות נייר אזמין אותם לפיקניק בירקון המצויר אפרוס מפה עם ריבועים אמרח כמה כריכים אכין להם בדיוק כאילו מה שהם צריכים כאילו מה שהם צריכים אחרי שאמות ירדו קצת טיפות מישהו יפלוט השמיים בוכים אחרי שאמות ישימו כיפות כמה שטרות בין זרי הפרחים אחרי שאמות הכול יישאר ממש כשהיה פה מאז מעולם אחרי שאשוט אשתקף בירקון לעוד רבע שנייה אזרום אל הים\tעחרי שעמוט יבואו פטהום ענסים בלי בושה הם חיבוק פבלני אכרי שאמוט יספרו בכלון בדיכות עתיכות ישפילו פנים עכרי שאמוט יגיאו איסית זרים הם זרים ישירו סירים אחרי שעמות בקול חרישי טסתוף הרחילות עת עבור אטרי אני עפתח בקבוק עם חמה ממחטות נייר עזמין הותם לפיקניכ בירכון עמצויר עפרבס מפא עם ריבועים עמרח חמה כריחים הקין לאם בדיוק כאילו מה שאם צריכים כאילו מא שהם צריחים עכרי שאמות ירדו קצת טיפות מיסעו יפלות עשמיים בבכים אחרי שאמבט ישימו כיפות חמא שתרוט בין זרי אפרחים אחרי סעמוט הקול יישהר ממש קשהיה פה מעז מהולם אכרי שעסוט עשתכף בירכון לאוד רבע שנייה הזרום אל אים\n",
            "<-----------= Example:\n",
            "\n",
            "\n",
            "\n",
            "Exporting the data to Excel file\n",
            "Conversion complete. Check hebrew_text_aug_30.xlsx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['errors', 'original'],\n",
              "     num_rows: 11634\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['errors', 'original'],\n",
              "     num_rows: 2909\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os.path\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "from datasets import Dataset, DatasetDict\n",
        "import torch\n",
        "import re\n",
        "\n",
        "\n",
        "def random_replace(string, default_prob):\n",
        "    replacements = {\n",
        "        'א': [('ע', default_prob), ('ה', default_prob)],\n",
        "        'ע': [('א', default_prob), ('ה', default_prob)],\n",
        "        'ה': [('א', default_prob), ('ע', default_prob)],\n",
        "\n",
        "        'ט': [('ת', default_prob)],\n",
        "        'ת': [('ט', default_prob)],\n",
        "\n",
        "        'ח': [('כ', default_prob)],\n",
        "        'כ': [('ח', default_prob), ('ק', default_prob)],\n",
        "        'ק': [('כ', default_prob)],\n",
        "\n",
        "        'ש': [('ס', default_prob / 2)],\n",
        "        'ס': [('ש', default_prob / 2)],\n",
        "\n",
        "        'ב': [('ו', default_prob / 4)],\n",
        "        'ו': [('ב', default_prob / 4)],\n",
        "\n",
        "        'לא ': ('לו ', default_prob),\n",
        "        'לו ': [('לא ', default_prob)]\n",
        "    }\n",
        "\n",
        "    # Convert string to list to make replacements\n",
        "    string_list = list(string)\n",
        "    for idx, char in enumerate(string_list):\n",
        "        if char in replacements:\n",
        "            for replacement, prob in replacements[char]:\n",
        "                if random.random() < prob:  # Unique probability for each replacement\n",
        "                    string_list[idx] = replacement\n",
        "                    break  # Stop after the first replacement\n",
        "    return ''.join(string_list)\n",
        "\n",
        "\n",
        "def create_augmentations(percentage=30, verbose=False, is_wiki=False):\n",
        "    default_prob = float(percentage) / 100\n",
        "    wiki_name = \"\"\n",
        "    if is_wiki:\n",
        "        wiki_name = \"_wiki\"\n",
        "\n",
        "    # input_txt_path = 'hebrew_text' + wiki_name + '.txt'\n",
        "    input_txt_path = 'hebrew_text.txt'\n",
        "    output_path = 'hebrew_text_aug_' + str(percentage)\n",
        "\n",
        "    # Read the input TXT file\n",
        "    with open(input_txt_path, 'r', encoding='utf-8') as infile:\n",
        "        lines = infile.readlines()\n",
        "\n",
        "    # Process each line\n",
        "    processed_lines = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        modified_line = random_replace(line, default_prob)\n",
        "        if line == '' or len(line) <= 2:\n",
        "            continue\n",
        "        processed_lines.append(f\"{line}\\t{modified_line}\")\n",
        "\n",
        "    if 'wiki' in input_txt_path:\n",
        "      # Keep only the strings with at least one hebrew letter in them\n",
        "      pattern = re.compile(r'[א-ת]')\n",
        "      processed_lines = [s for s in processed_lines if pattern.search(s)]\n",
        "      # Remove strings with English letters\n",
        "      pattern = re.compile(r'[a-zA-Z]')\n",
        "      processed_lines = [s for s in processed_lines if not pattern.search(s)]\n",
        "\n",
        "    if verbose:\n",
        "        print(f'-----------> Example:\\n\\n')\n",
        "        print(processed_lines[1])\n",
        "        print(f'<-----------= Example:\\n\\n')\n",
        "\n",
        "    # Save data in txt format - uncomment to activate\n",
        "    # # Write the original and modified text to the output TXT file\n",
        "    # output_txt_path = output_path + '.txt'\n",
        "    # with open(output_txt_path, 'w', encoding='utf-8') as outfile:\n",
        "    #     outfile.write('\\n'.join(processed_lines))\n",
        "    #\n",
        "    # print(f\"Modified data saved to {output_txt_path}\")\n",
        "\n",
        "    print(f'\\nExporting the data to Excel file')\n",
        "\n",
        "    processed_lines = processed_lines[1:]\n",
        "    data = [line.strip().split('\\t') for line in processed_lines]\n",
        "    if 'wiki' in input_txt_path:\n",
        "        df = pd.DataFrame(data)\n",
        "        df.columns = ['original', 'errors'] + df.columns[2:].tolist()\n",
        "    else:\n",
        "        df = pd.DataFrame(data, columns=['original', 'errors'])  # Adjust column names as needed\n",
        "    excel_output_path = output_path + '.xlsx'\n",
        "    df.to_excel(excel_output_path, index=False, engine='openpyxl')\n",
        "\n",
        "    print(f\"Conversion complete. Check {excel_output_path}\")\n",
        "    return excel_output_path\n",
        "\n",
        "\n",
        "def export_dataset(excel_path):\n",
        "    df = pd.read_excel(excel_path)\n",
        "    df.dropna(subset=['errors', 'original'], inplace=True)\n",
        "    texts_with_errors = df['errors'].tolist()\n",
        "    texts_corrected = df['original'].tolist()\n",
        "\n",
        "    data_dict = {\n",
        "        'errors': texts_with_errors,\n",
        "        'original': texts_corrected\n",
        "    }\n",
        "\n",
        "    # dataset = ds.Dataset.from_dict(data_dict)\n",
        "    dataset = Dataset.from_dict(data_dict)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def export_train_test_dataset(excel_path, test_size=0.2):\n",
        "    if (not os.path.exists('train.pt')) and (not os.path.exists('test.pt')):\n",
        "        dataset = export_dataset(excel_path)\n",
        "        # Split the dataset into training and testing sets\n",
        "        train_test_split = dataset.train_test_split(test_size=test_size)\n",
        "        torch.save(train_test_split['train'], 'train.pt')\n",
        "        torch.save(train_test_split['test'], 'test.pt')\n",
        "\n",
        "        return train_test_split['train'], train_test_split['test']\n",
        "    else:\n",
        "        train_split = torch.load('train.pt')\n",
        "        test_split = torch.load('test.pt')\n",
        "        return train_split, test_split\n",
        "\n",
        "\n",
        "\n",
        "def full_run(percentage=30, verbose=False):\n",
        "    return export_dataset(create_augmentations(percentage, verbose))\n",
        "\n",
        "\n",
        "def full_run_train_test_split(percentage=30, verbose=True):\n",
        "    return export_train_test_dataset(create_augmentations(percentage, verbose))\n",
        "\n",
        "\n",
        "full_run_train_test_split()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjtxwoHiG-3H"
      },
      "source": [
        "# transformer_prepare_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkS8SbWfIPbt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "# import tensorflow as tf\n",
        "# from create_augmentations import *\n",
        "from transformers import BertTokenizer, BatchEncoding, T5Tokenizer, T5ForConditionalGeneration, MT5Tokenizer, MT5ForConditionalGeneration\n",
        "from datasets import load_from_disk\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from transformers import BertForSequenceClassification\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "X_NAME = 'errors'  # Todo: change names\n",
        "Y_NAME = 'original'\n",
        "\n",
        "# ---------- HYPERPARAMETERS -----------\n",
        "# -------------------------------------->\n",
        "max_length = 128\n",
        "# <--------------------------------------\n",
        "\n",
        "\n",
        "# --------- HELPER FUNCTIONS -----------\n",
        "# -------------------------------------->\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask']}\n",
        "        # Ensure labels are correctly indexed\n",
        "        if isinstance(self.labels, BatchEncoding):\n",
        "            item['labels'] = self.labels['input_ids'][idx]  # Adjust according to how labels are stored\n",
        "        else:\n",
        "            item['labels'] = self.labels[idx].clone().detach()\n",
        "\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        # return len(self.labels)\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, inputs, targets, tokenizer, max_length=128):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        print(f\"Index: {idx}, Type: {type(idx)}\")\n",
        "        if isinstance(idx, list):\n",
        "            raise ValueError(\"Index must be an integer, not a list\")\n",
        "\n",
        "        input_text = self.inputs[idx]\n",
        "        target_text = self.targets[idx]\n",
        "\n",
        "        input_encoding = self.tokenizer(\n",
        "            input_text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        target_encoding = self.tokenizer(\n",
        "            target_text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
        "            'labels': target_encoding['input_ids'].squeeze()\n",
        "        }\n",
        "\n",
        "# <--------------------------------------\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    # model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
        "    # tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "    # model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "    # tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "    model_name = \"google/mt5-base\"\n",
        "    tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
        "    model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "    # --------- FREEZING LAYERS ------------\n",
        "    # -------------------------------------->\n",
        "\n",
        "    # for name, param in model.named_parameters():\n",
        "    #     if name.startswith(\"encoder.block.2.\"):\n",
        "    #         param.requires_grad = False\n",
        "\n",
        "    # for name, param in model.named_parameters():\n",
        "    #     if name.startswith(\"encoder.block.3.\"):\n",
        "    #         param.requires_grad = False\n",
        "\n",
        "    # for name, param in model.named_parameters():\n",
        "    #     if name.startswith(\"encoder.block.4.\"):\n",
        "    #         param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"encoder.block.5.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"encoder.block.6.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"encoder.block.7.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"decoder.block.0.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"decoder.block.1.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"decoder.block.2.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"decoder.block.3.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"decoder.block.4.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"decoder.block.5.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # for name, param in model.named_parameters():\n",
        "    #     if name.startswith(\"decoder.block.6.\"):\n",
        "    #         param.requires_grad = False\n",
        "\n",
        "    # <--------------------------------------\n",
        "\n",
        "    # ----------SEEING THE MODEL------------\n",
        "    # -------------------------------------->\n",
        "    print('Printing the layers of the model')\n",
        "    for name, param in model.named_parameters():\n",
        "        print(name, param.requires_grad)\n",
        "    # <--------------------------------------\n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "def prepare_data(tokenizer, num_train=None, num_test=None):\n",
        "    # -------------- DATASET ---------------\n",
        "    # -------------------------------------->\n",
        "    dataset_train, dataset_test = full_run_train_test_split(verbose=False)\n",
        "    dataset_train.set_format('pytorch')\n",
        "    dataset_test.set_format('pytorch')\n",
        "    train_inputs = dataset_train[X_NAME]\n",
        "    train_labels = dataset_train[Y_NAME]\n",
        "    test_inputs = dataset_test[X_NAME]\n",
        "    test_labels = dataset_test[Y_NAME]\n",
        "\n",
        "    if num_train is not None and num_train > 0:\n",
        "      print(f'Number of training samples = {num_train}')\n",
        "      train_inputs = train_inputs[:num_train]\n",
        "      train_labels = train_labels[:num_train]\n",
        "    if num_test is not None and num_test > 0:\n",
        "      print(f'Number of test samples = {num_test}')\n",
        "      test_inputs = test_inputs[:num_test]\n",
        "      test_labels = test_labels[:num_test]\n",
        "\n",
        "\n",
        "    def truncate_sentences(sentences, sentences_target):\n",
        "        truncated_sentences = []\n",
        "        truncated_sentences_targets = []\n",
        "        for sentence, label in zip(sentences, sentences_target):\n",
        "            words = sentence.split()\n",
        "            labels = label.split()\n",
        "            num_words = random.randint(1, 13)  # Random number between 1 and 13\n",
        "            truncated_sentence = ' '.join(words[:num_words])\n",
        "            truncated_sentence_target = ' '.join(labels[:num_words])\n",
        "            truncated_sentences.append(truncated_sentence)\n",
        "            truncated_sentences_targets.append(truncated_sentence_target)\n",
        "        print('----------------------')\n",
        "        print('Data after truncation:')\n",
        "        print(f'truncated input:\\n{truncated_sentences[1]}')\n",
        "        print(f'truncated label:\\n{truncated_sentences_targets[1]}')\n",
        "        print('----------------------')\n",
        "        return truncated_sentences, truncated_sentences_targets\n",
        "\n",
        "    train_inputs, train_labels = truncate_sentences(train_inputs, train_labels)\n",
        "    test_inputs, test_labels = truncate_sentences(test_inputs, test_labels)\n",
        "\n",
        "    train_input_tokenized = tokenizer(train_inputs, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
        "    train_labels_tokenized = tokenizer(train_labels, truncation=True, padding=True, max_length=max_length, return_tensors='pt').input_ids\n",
        "    test_input_tokenized = tokenizer(test_inputs, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
        "    test_labels_tokenized = tokenizer(test_labels, truncation=True, padding=True, max_length=max_length, return_tensors='pt').input_ids\n",
        "\n",
        "    text_tensor_train_ds = TextDataset(train_input_tokenized, train_labels_tokenized)\n",
        "    text_tensor_test_ds = TextDataset(test_input_tokenized, test_labels_tokenized)\n",
        "\n",
        "    # text_tensor_train_ds = Seq2SeqDataset(train_input_tokenized, train_labels_tokenized, tokenizer, max_length=128)\n",
        "    # text_tensor_test_ds = Seq2SeqDataset(test_input_tokenized, test_labels_tokenized, tokenizer, max_length=128)\n",
        "\n",
        "    # Save the datasets to disk\n",
        "    # torch.save(text_tensor_train_ds, 'tokenized/text_tensor_train_ds.pt')\n",
        "    # torch.save(text_tensor_test_ds, 'tokenized/text_tensor_test_ds.pt')\n",
        "    return text_tensor_train_ds, text_tensor_test_ds\n",
        "\n",
        "\n",
        "def get_model_and_data(path_to_data='tokenized', num_train=None, num_test=None):\n",
        "    model, tokenizer = get_model()\n",
        "    # prepare_data(tokenizer)  # todo: remove this line\n",
        "    text_tensor_train_ds, text_tensor_test_ds = prepare_data(tokenizer, num_train, num_test)\n",
        "\n",
        "    return model, tokenizer, text_tensor_train_ds, text_tensor_test_ds\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbF_KlusHDfp"
      },
      "source": [
        "# transformer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoDdkB5jITRM",
        "outputId": "0ce6401e-49eb-4a12-d07b-df601fad00ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing the layers of the model\n",
            "shared.weight True\n",
            "encoder.block.0.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.0.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.0.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.0.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight True\n",
            "encoder.block.0.layer.0.layer_norm.weight True\n",
            "encoder.block.0.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.0.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.0.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.0.layer.1.layer_norm.weight True\n",
            "encoder.block.1.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.1.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.1.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.1.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.1.layer.0.layer_norm.weight True\n",
            "encoder.block.1.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.1.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.1.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.1.layer.1.layer_norm.weight True\n",
            "encoder.block.2.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.2.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.2.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.2.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.2.layer.0.layer_norm.weight True\n",
            "encoder.block.2.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.2.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.2.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.2.layer.1.layer_norm.weight True\n",
            "encoder.block.3.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.3.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.3.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.3.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.3.layer.0.layer_norm.weight True\n",
            "encoder.block.3.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.3.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.3.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.3.layer.1.layer_norm.weight True\n",
            "encoder.block.4.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.4.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.4.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.4.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.4.layer.0.layer_norm.weight True\n",
            "encoder.block.4.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.4.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.4.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.4.layer.1.layer_norm.weight True\n",
            "encoder.block.5.layer.0.SelfAttention.q.weight False\n",
            "encoder.block.5.layer.0.SelfAttention.k.weight False\n",
            "encoder.block.5.layer.0.SelfAttention.v.weight False\n",
            "encoder.block.5.layer.0.SelfAttention.o.weight False\n",
            "encoder.block.5.layer.0.layer_norm.weight False\n",
            "encoder.block.5.layer.1.DenseReluDense.wi_0.weight False\n",
            "encoder.block.5.layer.1.DenseReluDense.wi_1.weight False\n",
            "encoder.block.5.layer.1.DenseReluDense.wo.weight False\n",
            "encoder.block.5.layer.1.layer_norm.weight False\n",
            "encoder.block.6.layer.0.SelfAttention.q.weight False\n",
            "encoder.block.6.layer.0.SelfAttention.k.weight False\n",
            "encoder.block.6.layer.0.SelfAttention.v.weight False\n",
            "encoder.block.6.layer.0.SelfAttention.o.weight False\n",
            "encoder.block.6.layer.0.layer_norm.weight False\n",
            "encoder.block.6.layer.1.DenseReluDense.wi_0.weight False\n",
            "encoder.block.6.layer.1.DenseReluDense.wi_1.weight False\n",
            "encoder.block.6.layer.1.DenseReluDense.wo.weight False\n",
            "encoder.block.6.layer.1.layer_norm.weight False\n",
            "encoder.block.7.layer.0.SelfAttention.q.weight False\n",
            "encoder.block.7.layer.0.SelfAttention.k.weight False\n",
            "encoder.block.7.layer.0.SelfAttention.v.weight False\n",
            "encoder.block.7.layer.0.SelfAttention.o.weight False\n",
            "encoder.block.7.layer.0.layer_norm.weight False\n",
            "encoder.block.7.layer.1.DenseReluDense.wi_0.weight False\n",
            "encoder.block.7.layer.1.DenseReluDense.wi_1.weight False\n",
            "encoder.block.7.layer.1.DenseReluDense.wo.weight False\n",
            "encoder.block.7.layer.1.layer_norm.weight False\n",
            "encoder.block.8.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.8.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.8.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.8.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.8.layer.0.layer_norm.weight True\n",
            "encoder.block.8.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.8.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.8.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.8.layer.1.layer_norm.weight True\n",
            "encoder.block.9.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.9.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.9.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.9.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.9.layer.0.layer_norm.weight True\n",
            "encoder.block.9.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.9.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.9.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.9.layer.1.layer_norm.weight True\n",
            "encoder.block.10.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.10.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.10.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.10.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.10.layer.0.layer_norm.weight True\n",
            "encoder.block.10.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.10.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.10.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.10.layer.1.layer_norm.weight True\n",
            "encoder.block.11.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.11.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.11.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.11.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.11.layer.0.layer_norm.weight True\n",
            "encoder.block.11.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.11.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.11.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.11.layer.1.layer_norm.weight True\n",
            "encoder.final_layer_norm.weight True\n",
            "decoder.block.0.layer.0.SelfAttention.q.weight False\n",
            "decoder.block.0.layer.0.SelfAttention.k.weight False\n",
            "decoder.block.0.layer.0.SelfAttention.v.weight False\n",
            "decoder.block.0.layer.0.SelfAttention.o.weight False\n",
            "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight False\n",
            "decoder.block.0.layer.0.layer_norm.weight False\n",
            "decoder.block.0.layer.1.EncDecAttention.q.weight False\n",
            "decoder.block.0.layer.1.EncDecAttention.k.weight False\n",
            "decoder.block.0.layer.1.EncDecAttention.v.weight False\n",
            "decoder.block.0.layer.1.EncDecAttention.o.weight False\n",
            "decoder.block.0.layer.1.layer_norm.weight False\n",
            "decoder.block.0.layer.2.DenseReluDense.wi_0.weight False\n",
            "decoder.block.0.layer.2.DenseReluDense.wi_1.weight False\n",
            "decoder.block.0.layer.2.DenseReluDense.wo.weight False\n",
            "decoder.block.0.layer.2.layer_norm.weight False\n",
            "decoder.block.1.layer.0.SelfAttention.q.weight False\n",
            "decoder.block.1.layer.0.SelfAttention.k.weight False\n",
            "decoder.block.1.layer.0.SelfAttention.v.weight False\n",
            "decoder.block.1.layer.0.SelfAttention.o.weight False\n",
            "decoder.block.1.layer.0.layer_norm.weight False\n",
            "decoder.block.1.layer.1.EncDecAttention.q.weight False\n",
            "decoder.block.1.layer.1.EncDecAttention.k.weight False\n",
            "decoder.block.1.layer.1.EncDecAttention.v.weight False\n",
            "decoder.block.1.layer.1.EncDecAttention.o.weight False\n",
            "decoder.block.1.layer.1.layer_norm.weight False\n",
            "decoder.block.1.layer.2.DenseReluDense.wi_0.weight False\n",
            "decoder.block.1.layer.2.DenseReluDense.wi_1.weight False\n",
            "decoder.block.1.layer.2.DenseReluDense.wo.weight False\n",
            "decoder.block.1.layer.2.layer_norm.weight False\n",
            "decoder.block.2.layer.0.SelfAttention.q.weight False\n",
            "decoder.block.2.layer.0.SelfAttention.k.weight False\n",
            "decoder.block.2.layer.0.SelfAttention.v.weight False\n",
            "decoder.block.2.layer.0.SelfAttention.o.weight False\n",
            "decoder.block.2.layer.0.layer_norm.weight False\n",
            "decoder.block.2.layer.1.EncDecAttention.q.weight False\n",
            "decoder.block.2.layer.1.EncDecAttention.k.weight False\n",
            "decoder.block.2.layer.1.EncDecAttention.v.weight False\n",
            "decoder.block.2.layer.1.EncDecAttention.o.weight False\n",
            "decoder.block.2.layer.1.layer_norm.weight False\n",
            "decoder.block.2.layer.2.DenseReluDense.wi_0.weight False\n",
            "decoder.block.2.layer.2.DenseReluDense.wi_1.weight False\n",
            "decoder.block.2.layer.2.DenseReluDense.wo.weight False\n",
            "decoder.block.2.layer.2.layer_norm.weight False\n",
            "decoder.block.3.layer.0.SelfAttention.q.weight False\n",
            "decoder.block.3.layer.0.SelfAttention.k.weight False\n",
            "decoder.block.3.layer.0.SelfAttention.v.weight False\n",
            "decoder.block.3.layer.0.SelfAttention.o.weight False\n",
            "decoder.block.3.layer.0.layer_norm.weight False\n",
            "decoder.block.3.layer.1.EncDecAttention.q.weight False\n",
            "decoder.block.3.layer.1.EncDecAttention.k.weight False\n",
            "decoder.block.3.layer.1.EncDecAttention.v.weight False\n",
            "decoder.block.3.layer.1.EncDecAttention.o.weight False\n",
            "decoder.block.3.layer.1.layer_norm.weight False\n",
            "decoder.block.3.layer.2.DenseReluDense.wi_0.weight False\n",
            "decoder.block.3.layer.2.DenseReluDense.wi_1.weight False\n",
            "decoder.block.3.layer.2.DenseReluDense.wo.weight False\n",
            "decoder.block.3.layer.2.layer_norm.weight False\n",
            "decoder.block.4.layer.0.SelfAttention.q.weight False\n",
            "decoder.block.4.layer.0.SelfAttention.k.weight False\n",
            "decoder.block.4.layer.0.SelfAttention.v.weight False\n",
            "decoder.block.4.layer.0.SelfAttention.o.weight False\n",
            "decoder.block.4.layer.0.layer_norm.weight False\n",
            "decoder.block.4.layer.1.EncDecAttention.q.weight False\n",
            "decoder.block.4.layer.1.EncDecAttention.k.weight False\n",
            "decoder.block.4.layer.1.EncDecAttention.v.weight False\n",
            "decoder.block.4.layer.1.EncDecAttention.o.weight False\n",
            "decoder.block.4.layer.1.layer_norm.weight False\n",
            "decoder.block.4.layer.2.DenseReluDense.wi_0.weight False\n",
            "decoder.block.4.layer.2.DenseReluDense.wi_1.weight False\n",
            "decoder.block.4.layer.2.DenseReluDense.wo.weight False\n",
            "decoder.block.4.layer.2.layer_norm.weight False\n",
            "decoder.block.5.layer.0.SelfAttention.q.weight False\n",
            "decoder.block.5.layer.0.SelfAttention.k.weight False\n",
            "decoder.block.5.layer.0.SelfAttention.v.weight False\n",
            "decoder.block.5.layer.0.SelfAttention.o.weight False\n",
            "decoder.block.5.layer.0.layer_norm.weight False\n",
            "decoder.block.5.layer.1.EncDecAttention.q.weight False\n",
            "decoder.block.5.layer.1.EncDecAttention.k.weight False\n",
            "decoder.block.5.layer.1.EncDecAttention.v.weight False\n",
            "decoder.block.5.layer.1.EncDecAttention.o.weight False\n",
            "decoder.block.5.layer.1.layer_norm.weight False\n",
            "decoder.block.5.layer.2.DenseReluDense.wi_0.weight False\n",
            "decoder.block.5.layer.2.DenseReluDense.wi_1.weight False\n",
            "decoder.block.5.layer.2.DenseReluDense.wo.weight False\n",
            "decoder.block.5.layer.2.layer_norm.weight False\n",
            "decoder.block.6.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.6.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.6.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.6.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.6.layer.0.layer_norm.weight True\n",
            "decoder.block.6.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.6.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.6.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.6.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.6.layer.1.layer_norm.weight True\n",
            "decoder.block.6.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.6.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.6.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.6.layer.2.layer_norm.weight True\n",
            "decoder.block.7.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.7.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.7.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.7.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.7.layer.0.layer_norm.weight True\n",
            "decoder.block.7.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.7.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.7.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.7.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.7.layer.1.layer_norm.weight True\n",
            "decoder.block.7.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.7.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.7.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.7.layer.2.layer_norm.weight True\n",
            "decoder.block.8.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.8.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.8.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.8.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.8.layer.0.layer_norm.weight True\n",
            "decoder.block.8.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.8.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.8.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.8.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.8.layer.1.layer_norm.weight True\n",
            "decoder.block.8.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.8.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.8.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.8.layer.2.layer_norm.weight True\n",
            "decoder.block.9.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.9.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.9.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.9.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.9.layer.0.layer_norm.weight True\n",
            "decoder.block.9.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.9.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.9.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.9.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.9.layer.1.layer_norm.weight True\n",
            "decoder.block.9.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.9.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.9.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.9.layer.2.layer_norm.weight True\n",
            "decoder.block.10.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.10.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.10.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.10.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.10.layer.0.layer_norm.weight True\n",
            "decoder.block.10.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.10.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.10.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.10.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.10.layer.1.layer_norm.weight True\n",
            "decoder.block.10.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.10.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.10.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.10.layer.2.layer_norm.weight True\n",
            "decoder.block.11.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.11.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.11.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.11.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.11.layer.0.layer_norm.weight True\n",
            "decoder.block.11.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.11.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.11.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.11.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.11.layer.1.layer_norm.weight True\n",
            "decoder.block.11.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.11.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.11.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.11.layer.2.layer_norm.weight True\n",
            "decoder.final_layer_norm.weight True\n",
            "lm_head.weight True\n",
            "\n",
            "Exporting the data to Excel file\n",
            "Conversion complete. Check hebrew_text_aug_30.xlsx\n",
            "Number of test samples = 1000\n",
            "----------------------\n",
            "Data after truncation:\n",
            "truncated input:\n",
            "עוד מעט ניגע באור הדף\n",
            "truncated label:\n",
            "עוד מעט ניגע באור הדף\n",
            "----------------------\n",
            "----------------------\n",
            "Data after truncation:\n",
            "truncated input:\n",
            "הני הוא עיס המוסיכה שסר שירים יפים לכל אילדות שכאן לחל אילדים\n",
            "truncated label:\n",
            "אני הוא איש המוסיקה ששר שירים יפים לכל הילדות שכאן לכל הילדים\n",
            "----------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MT5ForConditionalGeneration(\n",
              "  (shared): Embedding(250112, 768)\n",
              "  (encoder): MT5Stack(\n",
              "    (embed_tokens): Embedding(250112, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): MT5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): MT5LayerSelfAttention(\n",
              "            (SelfAttention): MT5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): MT5LayerFF(\n",
              "            (DenseReluDense): MT5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x MT5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): MT5LayerSelfAttention(\n",
              "            (SelfAttention): MT5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): MT5LayerFF(\n",
              "            (DenseReluDense): MT5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): MT5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): MT5Stack(\n",
              "    (embed_tokens): Embedding(250112, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): MT5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): MT5LayerSelfAttention(\n",
              "            (SelfAttention): MT5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): MT5LayerCrossAttention(\n",
              "            (EncDecAttention): MT5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): MT5LayerFF(\n",
              "            (DenseReluDense): MT5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x MT5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): MT5LayerSelfAttention(\n",
              "            (SelfAttention): MT5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): MT5LayerCrossAttention(\n",
              "            (EncDecAttention): MT5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): MT5LayerFF(\n",
              "            (DenseReluDense): MT5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): MT5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=250112, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# from datasets import Dataset\n",
        "# from create_augmentations import *\n",
        "# from datasets import load_from_disk\n",
        "# import os\n",
        "# import torch.nn as nn\n",
        "# from torch.utils.data import DataLoader, TensorDataset\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from transformers import BertForSequenceClassification\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from transformers import BertTokenizer, TrainingArguments, Trainer, BatchEncoding, TrainerCallback\n",
        "# from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "# import torch\n",
        "# from transformer_prepare_data import *\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "from tqdm.auto import tqdm\n",
        "import evaluate\n",
        "from torch.optim.lr_scheduler import ChainedScheduler, ExponentialLR\n",
        "\n",
        "\n",
        "# ---------- HYPERPARAMETERS -----------\n",
        "# -------------------------------------->\n",
        "BATCH_SIZE = 32\n",
        "num_epochs = 15\n",
        "num_train = None\n",
        "num_test = 1000\n",
        "lr = 1e-3\n",
        "# <--------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Load the saved datasets\n",
        "model, tokenizer, text_tensor_train_ds, text_tensor_test_ds = get_model_and_data(num_train=num_train, num_test=num_test)\n",
        "# text_tensor_train_ds = torch.load('tokenized/text_tensor_train_ds.pt')\n",
        "# text_tensor_test_ds = torch.load('tokenized/text_tensor_test_ds.pt')\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
        "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
        "    labels = torch.stack([item['labels'] for item in batch])\n",
        "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(text_tensor_train_ds, shuffle=True, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(text_tensor_test_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "\n",
        "#optimizer = AdamW(model.parameters(), lr=5e-3, weight_decay=0.01)\n",
        "from transformers import Adafactor\n",
        "optimizer = Adafactor(model.parameters(), scale_parameter=False, relative_step=False, warmup_init=False, lr=lr)\n",
        "\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "\n",
        "cosine_scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=100,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "\n",
        "# Exponential decay scheduler\n",
        "exp_scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "# Chain the schedulers together\n",
        "lr_scheduler = ChainedScheduler([cosine_scheduler, exp_scheduler])\n",
        "\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691,
          "referenced_widgets": [
            "453db987b712404c88f0fca03289c091",
            "d6810788a2d9413fae57701c043b537b",
            "d8d63de22c164ed58670f31833eae8c3",
            "19607de67f5d479794266acc1359f768",
            "9279b34088ed4591bfaf8745097a399a",
            "06da4ffa5f934ca6a91a1bbc99d09af6",
            "97df8cd5aed94afd9646b6cc623a680b",
            "8fbf449472fc4c799e5be6bb3c752ea3",
            "4071e828e1034c94966904e313dec5cc",
            "2bddddeed3b74159a0d6cd29998fc5ed",
            "c5fcdbf5313f409885de3cedbef00610"
          ]
        },
        "id": "p8q5XFfLISft",
        "outputId": "12286d44-6ab4-4f90-aae2-592d20d0d186"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5460 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "453db987b712404c88f0fca03289c091"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/15, Training Loss: 5.2690\n",
            "Current state: ביט פנסים דולכים עלי\n",
            "Target: בית פנסים דולקים עלי\n",
            "Prediction: ביט פנסים ביט פנסים דול\n",
            "Test Loss: 1.4555, Test Accuracy: 0.3830  learning reate: 0.0008946235719291715\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_394e43c6-70d3-459d-afe6-b5a2073c3686\", \"saved_model_checkout.pth\", 2329738372)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/15, Training Loss: 1.1166\n",
            "Current state: בס כל חך הרבא\n",
            "Target: בס כל כך הרבה\n",
            "Prediction: בסך כל כך כל כך כל כך כל כך הרבא\n",
            "Test Loss: 0.7377, Test Accuracy: 0.6648  learning reate: 0.0008698586237784118\n",
            "\n",
            "Epoch 3/15, Training Loss: 0.6441\n",
            "Current state: למות צעירע למות לא לה רציטי\n",
            "Target: למות צעירה למות לא לא רציתי\n",
            "Prediction: למות רציתי\n",
            "Test Loss: 0.4672, Test Accuracy: 0.7605  learning reate: 0.0008260553796883374\n",
            "\n",
            "Epoch 4/15, Training Loss: 0.4351\n",
            "Current state: בס כל חך הרבא\n",
            "Target: בס כל כך הרבה\n",
            "Prediction: בסך הכל כך הרבא\n",
            "Test Loss: 0.3415, Test Accuracy: 0.8112  learning reate: 0.0007652000775896689\n",
            "\n",
            "Epoch 5/15, Training Loss: 0.3218\n",
            "Current state: לב חולה הלילא פרידא אכת יותר מדי הזבט\n",
            "Target: לב חולה הלילה פרידה אחת יותר מדי עזבת\n",
            "Prediction: לב חולה הלילה פרידה את יותר מדי הזבת\n",
            "Test Loss: 0.2940, Test Accuracy: 0.8322  learning reate: 0.0006900521731306067\n",
            "\n",
            "Epoch 6/15, Training Loss: 0.2564\n",
            "Current state: למות צעירע למות לא לה רציטי\n",
            "Target: למות צעירה למות לא לא רציתי\n",
            "Prediction: למות צעירה למות לא לא רציתי\n",
            "Test Loss: 0.2585, Test Accuracy: 0.8532  learning reate: 0.0006040192134312641\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "def calc_accuracy(model, tokenizer, test_dataloader):\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    total_examples = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
        "        for batch in test_dataloader:\n",
        "            batch = {key: value.to(device) for key, value in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Generate predictions\n",
        "            #generated_tokens = model.generate(batch['input_ids'], max_length=batch['labels'].shape[1])\n",
        "\n",
        "            # Decode the generated tokens and labels to text\n",
        "            #generated_texts = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "            #labels_texts = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
        "\n",
        "            # Calculate accuracy by comparing generated texts to target texts\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            predictions = predictions.view(-1)\n",
        "            references = batch[\"labels\"].view(-1)\n",
        "            mask = references != tokenizer.pad_token_id\n",
        "            predictions = predictions[mask]\n",
        "            references = references[mask]\n",
        "\n",
        "            metric.add_batch(predictions=predictions, references=references)\n",
        "\n",
        "    avg_test_loss = total_loss / len(test_dataloader)\n",
        "    accuracy_dict = metric.compute()\n",
        "    accuracy = float(accuracy_dict['accuracy'])\n",
        "    random_index = random.randint(0, len(batch['labels']) - 1)\n",
        "    random_target = tokenizer.decode(batch['labels'][random_index], skip_special_tokens=True)\n",
        "    random_prediction = tokenizer.decode(generated_tokens[random_index], skip_special_tokens=True)\n",
        "    random_current = tokenizer.decode(batch['input_ids'][random_index], skip_special_tokens=True)\n",
        "    #print(f'Current state:\\nTarget: {labels_texts[random_index]}\\nPrediction: {generated_texts[random_index]}')\n",
        "    print(f'Current state: {random_current}\\nTarget: {random_target}\\nPrediction: {random_prediction}')\n",
        "\n",
        "    model.train()  # Set the model back to training mode\n",
        "    return avg_test_loss, accuracy\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model.train()\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "best_accuracy = np.inf\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        batch = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        epoch_loss += loss.item()  # Accumulate the loss\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_train_loss = epoch_loss / len(train_dataloader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # -------------------------------------------\n",
        "    model.eval()\n",
        "    avg_test_loss, accuracy = calc_accuracy(model, tokenizer, test_dataloader)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    test_accuracies.append(accuracy)\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.4f}  learning reate: {optimizer.param_groups[0]['lr']}\")\n",
        "    # Set the model back to training mode\n",
        "    model.train()\n",
        "    # -------------------------------------------\n",
        "\n",
        "    # Saving checkout\n",
        "    if accuracy < best_accuracy:\n",
        "      best_accuracy = accuracy\n",
        "      torch.save(model.state_dict(), 'saved_model_checkout.pth')\n",
        "      #files.download('saved_model_checkout.pth')\n",
        "      # Save the model to your Google Drive\n",
        "      torch.save(model.state_dict(), '/content/drive/My Drive/saved_model.pth')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'saved_model.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWZFD2lz1qrv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_testing_steps = len(test_dataloader)\n",
        "progress_bar_test = tqdm(range(num_testing_steps))\n",
        "\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "model.eval()\n",
        "for batch in test_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    # metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    # Flatten predictions and references\n",
        "    predictions = predictions.view(-1)\n",
        "    references = batch[\"labels\"].view(-1)\n",
        "\n",
        "    # Filter out padding tokens (if applicable)\n",
        "    mask = references != tokenizer.pad_token_id\n",
        "    predictions = predictions[mask]\n",
        "    references = references[mask]\n",
        "\n",
        "    metric.add_batch(predictions=predictions, references=references)\n",
        "    progress_bar_test.update(1)\n",
        "\n",
        "\n",
        "# Compute the final accuracy\n",
        "final_score = metric.compute()\n",
        "print(\"\\nAccuracy:\", final_score)\n",
        "\n",
        "\n",
        "# Plotting the loss and accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training and test loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
        "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# Plot test accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), test_accuracies, label='Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE308_1BEIJN"
      },
      "source": [
        "# Checking the trained model\n",
        "### check_model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaqaYub7fKde",
        "outputId": "620e13ef-fff5-49b0-ab5d-7a9c525cf05c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions:\n",
            "Input: זה למשל דוגמא אם שגיעה\n",
            "Output: זה למשל דוגמא עם שגיעה\n",
            "\n",
            "Input: עוד טקסט לטיקון\n",
            "Output: עוד טקסט לתיקון\n",
            "\n",
            "Input: הנה טאות\n",
            "Output: הנה טעות\n",
            "\n",
            "Input: לא הני\n",
            "Output: לא אני\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "# from transformer_prepare_data import *\n",
        "\n",
        "# model, tokenizer = get_model_and_data()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "# Sample data for inference\n",
        "new_data = [\"זה למשל דוגמא אם שגיעה\", \"עוד טקסט לטיקון\", \"הנה טאות\", \"לא הני\"]\n",
        "new_data_tokenized = tokenizer(\n",
        "    new_data, max_length=128, padding='max_length', truncation=True, return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Move data to device\n",
        "input_ids = new_data_tokenized['input_ids'].to(device)\n",
        "attention_mask = new_data_tokenized['attention_mask'].to(device)\n",
        "# print(\"Tokenized Input IDs:\", input_ids)\n",
        "# print(\"Attention Mask:\", attention_mask)\n",
        "\n",
        "# model.load_state_dict(torch.load('spellcheck_model/saved_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=128,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "\n",
        "predictions = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_ids]\n",
        "print(\"Predictions:\")\n",
        "for i, pred in enumerate(predictions):\n",
        "    print(f\"Input: {new_data[i]}\")\n",
        "    print(f\"Output: {pred}\")\n",
        "    print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBmJ3CoHECMh"
      },
      "source": [
        "# Sanity check that the used tokenizer works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HWq6LxsgeSA",
        "outputId": "6f65bc37-ecd1-4c7f-8c98-7d1db95418a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input: שגיאה\n",
            "input_encoded: [83407, 49491, 1]\n",
            "input_decoded: שגיאה\n"
          ]
        }
      ],
      "source": [
        "# predictions = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_ids]\n",
        "input = \"שגיאה\"\n",
        "input_encoded = tokenizer.encode(input)\n",
        "input_decoded = tokenizer.decode(input_encoded, skip_special_tokens=True)\n",
        "\n",
        "print(f'input: {input}')\n",
        "print(f'input_encoded: {input_encoded}')\n",
        "print(f'input_decoded: {input_decoded}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QP5P0oZXNPi0",
        "outputId": "86266bb5-a76a-450c-e67c-fc7e8e3677cf"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_c55c9381-315f-4a2e-bec4-b52c7a139c45\", \"saved_model.pth\", 1200795070)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# files.download('saved_model_checkout.pth')\n",
        "files.download('saved_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48usSr-NRC-u"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Save the model to your Google Drive\n",
        "# torch.save(model.state_dict(), '/content/drive/My Drive/saved_model.pth')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "453db987b712404c88f0fca03289c091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6810788a2d9413fae57701c043b537b",
              "IPY_MODEL_d8d63de22c164ed58670f31833eae8c3",
              "IPY_MODEL_19607de67f5d479794266acc1359f768"
            ],
            "layout": "IPY_MODEL_9279b34088ed4591bfaf8745097a399a"
          }
        },
        "d6810788a2d9413fae57701c043b537b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06da4ffa5f934ca6a91a1bbc99d09af6",
            "placeholder": "​",
            "style": "IPY_MODEL_97df8cd5aed94afd9646b6cc623a680b",
            "value": " 40%"
          }
        },
        "d8d63de22c164ed58670f31833eae8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fbf449472fc4c799e5be6bb3c752ea3",
            "max": 5460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4071e828e1034c94966904e313dec5cc",
            "value": 2191
          }
        },
        "19607de67f5d479794266acc1359f768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bddddeed3b74159a0d6cd29998fc5ed",
            "placeholder": "​",
            "style": "IPY_MODEL_c5fcdbf5313f409885de3cedbef00610",
            "value": " 2190/5460 [51:05&lt;2:46:54,  3.06s/it]"
          }
        },
        "9279b34088ed4591bfaf8745097a399a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06da4ffa5f934ca6a91a1bbc99d09af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97df8cd5aed94afd9646b6cc623a680b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fbf449472fc4c799e5be6bb3c752ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4071e828e1034c94966904e313dec5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bddddeed3b74159a0d6cd29998fc5ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5fcdbf5313f409885de3cedbef00610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}