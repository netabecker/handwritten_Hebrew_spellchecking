{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIBiSiesJ7zM",
        "outputId": "81bc1d37-7c5b-4167-d9bb-06f22bf26b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vaIQ7JcRH5Rq"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "\n",
        "def random_replace(string, default_prob):\n",
        "    replacements = {\n",
        "        'א': [('ע', default_prob), ('ה', default_prob)],\n",
        "        'ע': [('א', default_prob), ('ה', default_prob)],\n",
        "        'ה': [('א', default_prob), ('ע', default_prob)],\n",
        "\n",
        "        'ט': [('ת', default_prob)],\n",
        "        'ת': [('ט', default_prob)],\n",
        "\n",
        "        'ח': [('כ', default_prob)],\n",
        "        'כ': [('ח', default_prob), ('ק', default_prob)],\n",
        "        'ק': [('כ', default_prob)],\n",
        "\n",
        "        'ש': [('ס', default_prob / 2)],\n",
        "        'ס': [('ש', default_prob / 2)],\n",
        "\n",
        "        'ב': [('ו', default_prob / 4)],\n",
        "        'ו': [('ב', default_prob / 4)],\n",
        "\n",
        "        'לא ': ('לו ', default_prob),\n",
        "        'לו ': [('לא ', default_prob)]\n",
        "    }\n",
        "\n",
        "    # Convert string to list to make replacements\n",
        "    string_list = list(string)\n",
        "    for idx, char in enumerate(string_list):\n",
        "        if char in replacements:\n",
        "            for replacement, prob in replacements[char]:\n",
        "                if random.random() < prob:  # Unique probability for each replacement\n",
        "                    string_list[idx] = replacement\n",
        "                    break  # Stop after the first replacement\n",
        "    return ''.join(string_list)\n",
        "\n",
        "\n",
        "def create_augmentations(percentage=30, verbose=False):\n",
        "    default_prob = float(percentage) / 100\n",
        "    input_txt_path = 'datasets/hebrew_text.txt'\n",
        "    output_path = 'datasets/hebrew_text_aug_' + str(percentage)\n",
        "\n",
        "    # Read the input TXT file\n",
        "    with open(input_txt_path, 'r', encoding='utf-8') as infile:\n",
        "        lines = infile.readlines()\n",
        "\n",
        "    # Process each line\n",
        "    processed_lines = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        modified_line = random_replace(line, default_prob)\n",
        "        processed_lines.append(f\"{line}\\t{modified_line}\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f'-----------> Example:\\n\\n')\n",
        "        print(processed_lines[1])\n",
        "        print(f'<-----------= Example:\\n\\n')\n",
        "\n",
        "    # Save data in txt format - uncomment to activate\n",
        "    # # Write the original and modified text to the output TXT file\n",
        "    # output_txt_path = output_path + '.txt'\n",
        "    # with open(output_txt_path, 'w', encoding='utf-8') as outfile:\n",
        "    #     outfile.write('\\n'.join(processed_lines))\n",
        "    #\n",
        "    # print(f\"Modified data saved to {output_txt_path}\")\n",
        "\n",
        "    print(f'\\nExporting the data to Excel file')\n",
        "\n",
        "    processed_lines = processed_lines[1:]\n",
        "    data = [line.strip().split('\\t') for line in processed_lines]\n",
        "    df = pd.DataFrame(data, columns=['original', 'errors'])  # Adjust column names as needed\n",
        "    excel_output_path = output_path + '.xlsx'\n",
        "    df.to_excel(excel_output_path, index=False, engine='openpyxl')\n",
        "\n",
        "    print(f\"Conversion complete. Check {excel_output_path}\")\n",
        "    return excel_output_path\n",
        "\n",
        "\n",
        "def export_dataset(excel_path):\n",
        "    df = pd.read_excel(excel_path)\n",
        "    df.dropna(subset=['errors', 'original'], inplace=True)\n",
        "    texts_with_errors = df['errors'].tolist()\n",
        "    texts_corrected = df['original'].tolist()\n",
        "\n",
        "    data_dict = {\n",
        "        'errors': texts_with_errors,\n",
        "        'original': texts_corrected\n",
        "    }\n",
        "\n",
        "    # dataset = ds.Dataset.from_dict(data_dict)\n",
        "    dataset = Dataset.from_dict(data_dict)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def export_train_test_dataset(excel_path, test_size=0.2):\n",
        "    if (not os.path.exists('datasets/train.pt')) and (not os.path.exists('datasets/test.pt')):\n",
        "        dataset = export_dataset(excel_path)\n",
        "        # Split the dataset into training and testing sets\n",
        "        train_test_split = dataset.train_test_split(test_size=test_size)\n",
        "        torch.save(train_test_split['train'], 'datasets/train.pt')\n",
        "        torch.save(train_test_split['test'], 'datasets/test.pt')\n",
        "\n",
        "        return train_test_split['train'], train_test_split['test']\n",
        "    else:\n",
        "        train_split = torch.load('datasets/train.pt')\n",
        "        test_split = torch.load('datasets/test.pt')\n",
        "        return train_split, test_split\n",
        "\n",
        "\n",
        "\n",
        "def full_run(percentage=30, verbose=False):\n",
        "    return export_dataset(create_augmentations(percentage, verbose))\n",
        "\n",
        "\n",
        "def full_run_train_test_split(percentage=30, verbose=True):\n",
        "    return export_train_test_dataset(create_augmentations(percentage, verbose))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "EkS8SbWfIPbt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "# import tensorflow as tf\n",
        "# from create_augmentations import *\n",
        "from transformers import BertTokenizer, BatchEncoding, T5Tokenizer, T5ForConditionalGeneration, MT5Tokenizer, MT5ForConditionalGeneration\n",
        "from datasets import load_from_disk\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from transformers import BertForSequenceClassification\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "X_NAME = 'errors'  # Todo: change names\n",
        "Y_NAME = 'original'\n",
        "\n",
        "# ---------- HYPERPARAMETERS -----------\n",
        "# -------------------------------------->\n",
        "max_length = 128\n",
        "# <--------------------------------------\n",
        "\n",
        "\n",
        "# --------- HELPER FUNCTIONS -----------\n",
        "# -------------------------------------->\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask']}\n",
        "        # Ensure labels are correctly indexed\n",
        "        if isinstance(self.labels, BatchEncoding):\n",
        "            item['labels'] = self.labels['input_ids'][idx]  # Adjust according to how labels are stored\n",
        "        else:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        # return len(self.labels)\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, inputs, targets, tokenizer, max_length=128):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        print(f\"Index: {idx}, Type: {type(idx)}\")\n",
        "        if isinstance(idx, list):\n",
        "            raise ValueError(\"Index must be an integer, not a list\")\n",
        "\n",
        "        input_text = self.inputs[idx]\n",
        "        target_text = self.targets[idx]\n",
        "\n",
        "        input_encoding = self.tokenizer(\n",
        "            input_text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        target_encoding = self.tokenizer(\n",
        "            target_text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
        "            'labels': target_encoding['input_ids'].squeeze()\n",
        "        }\n",
        "\n",
        "# <--------------------------------------\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    # model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
        "    # tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "    # model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "    # tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "    model_name = \"google/mt5-small\"\n",
        "    tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
        "    model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "    # --------- FREEZING LAYERS ------------\n",
        "    # -------------------------------------->\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"encoder.block.4.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"encoder.block.5.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"encoder.block.6.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"encoder.block.7.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"decoder.block.3.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"decoder.block.4.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"decoder.block.5.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"decoder.block.6.\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # <--------------------------------------\n",
        "\n",
        "    # ----------SEEING THE MODEL------------\n",
        "    # -------------------------------------->\n",
        "    print('Printing the layers of the model')\n",
        "    for name, param in model.named_parameters():\n",
        "        print(name, param.requires_grad)\n",
        "    # <--------------------------------------\n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "def prepare_data(tokenizer, low_mem=True):\n",
        "    # -------------- DATASET ---------------\n",
        "    # -------------------------------------->\n",
        "    dataset_train, dataset_test = full_run_train_test_split(verbose=False)\n",
        "    dataset_train.set_format('pytorch')\n",
        "    dataset_test.set_format('pytorch')\n",
        "    train_inputs = dataset_train[X_NAME]\n",
        "    train_labels = dataset_train[Y_NAME]\n",
        "    test_inputs = dataset_test[X_NAME]\n",
        "    test_labels = dataset_test[Y_NAME]\n",
        "\n",
        "    if low_mem:\n",
        "      print(f'Making the sets smaller due to low available memory')\n",
        "      train_inputs = train_inputs[:500]\n",
        "      train_labels = train_labels[:500]\n",
        "      test_inputs = test_inputs[:100]\n",
        "      test_labels = test_labels[:100]\n",
        "\n",
        "    train_input_tokenized = tokenizer(train_inputs, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
        "    train_labels_tokenized = tokenizer(train_labels, truncation=True, padding=True, max_length=max_length, return_tensors='pt').input_ids\n",
        "    test_input_tokenized = tokenizer(test_inputs, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
        "    test_labels_tokenized = tokenizer(test_labels, truncation=True, padding=True, max_length=max_length, return_tensors='pt').input_ids\n",
        "\n",
        "    text_tensor_train_ds = TextDataset(train_input_tokenized, train_labels_tokenized)\n",
        "    text_tensor_test_ds = TextDataset(test_input_tokenized, test_labels_tokenized)\n",
        "\n",
        "    # text_tensor_train_ds = Seq2SeqDataset(train_input_tokenized, train_labels_tokenized, tokenizer, max_length=128)\n",
        "    # text_tensor_test_ds = Seq2SeqDataset(test_input_tokenized, test_labels_tokenized, tokenizer, max_length=128)\n",
        "\n",
        "    # Save the datasets to disk\n",
        "    # torch.save(text_tensor_train_ds, 'datasets/tokenized/text_tensor_train_ds.pt')\n",
        "    # torch.save(text_tensor_test_ds, 'datasets/tokenized/text_tensor_test_ds.pt')\n",
        "    return text_tensor_train_ds, text_tensor_test_ds\n",
        "\n",
        "\n",
        "def get_model_and_data(path_to_data='datasets/tokenized', low_mem=True):\n",
        "    model, tokenizer = get_model()\n",
        "    # prepare_data(tokenizer)  # todo: remove this line\n",
        "    text_tensor_train_ds, text_tensor_test_ds = prepare_data(tokenizer, low_mem)\n",
        "\n",
        "    return model, tokenizer, text_tensor_train_ds, text_tensor_test_ds\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bb93d83fdd3743ae8047025305d527d5",
            "da0be24e821344be84e88159a889ff00",
            "ae76200212d046b4875faf77c161a4a1",
            "ad242f16c8ce4b24b43984f96dd956d2",
            "825eca40e75e4e108c2dd46553b4c706",
            "7f23530a3c534ae2ae9e52c481ce320f",
            "6afb6f1dd6b2485a8f0321d475a197d8",
            "4235ebc3193841738b5137eeeecc0a8f",
            "b2597571a875437392135d070bc8bba9",
            "5b490acd58f64dd08a765b5128014f96",
            "7431704876d44438a157e91aef9f3d83"
          ]
        },
        "id": "QoDdkB5jITRM",
        "outputId": "5874fcd7-7007-4604-ea66-938219051bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing the layers of the model\n",
            "shared.weight True\n",
            "encoder.block.0.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.0.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.0.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.0.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight True\n",
            "encoder.block.0.layer.0.layer_norm.weight True\n",
            "encoder.block.0.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.0.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.0.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.0.layer.1.layer_norm.weight True\n",
            "encoder.block.1.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.1.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.1.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.1.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.1.layer.0.layer_norm.weight True\n",
            "encoder.block.1.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.1.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.1.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.1.layer.1.layer_norm.weight True\n",
            "encoder.block.2.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.2.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.2.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.2.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.2.layer.0.layer_norm.weight True\n",
            "encoder.block.2.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.2.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.2.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.2.layer.1.layer_norm.weight True\n",
            "encoder.block.3.layer.0.SelfAttention.q.weight True\n",
            "encoder.block.3.layer.0.SelfAttention.k.weight True\n",
            "encoder.block.3.layer.0.SelfAttention.v.weight True\n",
            "encoder.block.3.layer.0.SelfAttention.o.weight True\n",
            "encoder.block.3.layer.0.layer_norm.weight True\n",
            "encoder.block.3.layer.1.DenseReluDense.wi_0.weight True\n",
            "encoder.block.3.layer.1.DenseReluDense.wi_1.weight True\n",
            "encoder.block.3.layer.1.DenseReluDense.wo.weight True\n",
            "encoder.block.3.layer.1.layer_norm.weight True\n",
            "encoder.block.4.layer.0.SelfAttention.q.weight False\n",
            "encoder.block.4.layer.0.SelfAttention.k.weight False\n",
            "encoder.block.4.layer.0.SelfAttention.v.weight False\n",
            "encoder.block.4.layer.0.SelfAttention.o.weight False\n",
            "encoder.block.4.layer.0.layer_norm.weight False\n",
            "encoder.block.4.layer.1.DenseReluDense.wi_0.weight False\n",
            "encoder.block.4.layer.1.DenseReluDense.wi_1.weight False\n",
            "encoder.block.4.layer.1.DenseReluDense.wo.weight False\n",
            "encoder.block.4.layer.1.layer_norm.weight False\n",
            "encoder.block.5.layer.0.SelfAttention.q.weight False\n",
            "encoder.block.5.layer.0.SelfAttention.k.weight False\n",
            "encoder.block.5.layer.0.SelfAttention.v.weight False\n",
            "encoder.block.5.layer.0.SelfAttention.o.weight False\n",
            "encoder.block.5.layer.0.layer_norm.weight False\n",
            "encoder.block.5.layer.1.DenseReluDense.wi_0.weight False\n",
            "encoder.block.5.layer.1.DenseReluDense.wi_1.weight False\n",
            "encoder.block.5.layer.1.DenseReluDense.wo.weight False\n",
            "encoder.block.5.layer.1.layer_norm.weight False\n",
            "encoder.block.6.layer.0.SelfAttention.q.weight False\n",
            "encoder.block.6.layer.0.SelfAttention.k.weight False\n",
            "encoder.block.6.layer.0.SelfAttention.v.weight False\n",
            "encoder.block.6.layer.0.SelfAttention.o.weight False\n",
            "encoder.block.6.layer.0.layer_norm.weight False\n",
            "encoder.block.6.layer.1.DenseReluDense.wi_0.weight False\n",
            "encoder.block.6.layer.1.DenseReluDense.wi_1.weight False\n",
            "encoder.block.6.layer.1.DenseReluDense.wo.weight False\n",
            "encoder.block.6.layer.1.layer_norm.weight False\n",
            "encoder.block.7.layer.0.SelfAttention.q.weight False\n",
            "encoder.block.7.layer.0.SelfAttention.k.weight False\n",
            "encoder.block.7.layer.0.SelfAttention.v.weight False\n",
            "encoder.block.7.layer.0.SelfAttention.o.weight False\n",
            "encoder.block.7.layer.0.layer_norm.weight False\n",
            "encoder.block.7.layer.1.DenseReluDense.wi_0.weight False\n",
            "encoder.block.7.layer.1.DenseReluDense.wi_1.weight False\n",
            "encoder.block.7.layer.1.DenseReluDense.wo.weight False\n",
            "encoder.block.7.layer.1.layer_norm.weight False\n",
            "encoder.final_layer_norm.weight True\n",
            "decoder.block.0.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.0.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.0.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.0.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight True\n",
            "decoder.block.0.layer.0.layer_norm.weight True\n",
            "decoder.block.0.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.0.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.0.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.0.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.0.layer.1.layer_norm.weight True\n",
            "decoder.block.0.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.0.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.0.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.0.layer.2.layer_norm.weight True\n",
            "decoder.block.1.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.1.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.1.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.1.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.1.layer.0.layer_norm.weight True\n",
            "decoder.block.1.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.1.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.1.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.1.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.1.layer.1.layer_norm.weight True\n",
            "decoder.block.1.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.1.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.1.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.1.layer.2.layer_norm.weight True\n",
            "decoder.block.2.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.2.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.2.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.2.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.2.layer.0.layer_norm.weight True\n",
            "decoder.block.2.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.2.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.2.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.2.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.2.layer.1.layer_norm.weight True\n",
            "decoder.block.2.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.2.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.2.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.2.layer.2.layer_norm.weight True\n",
            "decoder.block.3.layer.0.SelfAttention.q.weight False\n",
            "decoder.block.3.layer.0.SelfAttention.k.weight False\n",
            "decoder.block.3.layer.0.SelfAttention.v.weight False\n",
            "decoder.block.3.layer.0.SelfAttention.o.weight False\n",
            "decoder.block.3.layer.0.layer_norm.weight False\n",
            "decoder.block.3.layer.1.EncDecAttention.q.weight False\n",
            "decoder.block.3.layer.1.EncDecAttention.k.weight False\n",
            "decoder.block.3.layer.1.EncDecAttention.v.weight False\n",
            "decoder.block.3.layer.1.EncDecAttention.o.weight False\n",
            "decoder.block.3.layer.1.layer_norm.weight False\n",
            "decoder.block.3.layer.2.DenseReluDense.wi_0.weight False\n",
            "decoder.block.3.layer.2.DenseReluDense.wi_1.weight False\n",
            "decoder.block.3.layer.2.DenseReluDense.wo.weight False\n",
            "decoder.block.3.layer.2.layer_norm.weight False\n",
            "decoder.block.4.layer.0.SelfAttention.q.weight False\n",
            "decoder.block.4.layer.0.SelfAttention.k.weight False\n",
            "decoder.block.4.layer.0.SelfAttention.v.weight False\n",
            "decoder.block.4.layer.0.SelfAttention.o.weight False\n",
            "decoder.block.4.layer.0.layer_norm.weight False\n",
            "decoder.block.4.layer.1.EncDecAttention.q.weight False\n",
            "decoder.block.4.layer.1.EncDecAttention.k.weight False\n",
            "decoder.block.4.layer.1.EncDecAttention.v.weight False\n",
            "decoder.block.4.layer.1.EncDecAttention.o.weight False\n",
            "decoder.block.4.layer.1.layer_norm.weight False\n",
            "decoder.block.4.layer.2.DenseReluDense.wi_0.weight False\n",
            "decoder.block.4.layer.2.DenseReluDense.wi_1.weight False\n",
            "decoder.block.4.layer.2.DenseReluDense.wo.weight False\n",
            "decoder.block.4.layer.2.layer_norm.weight False\n",
            "decoder.block.5.layer.0.SelfAttention.q.weight False\n",
            "decoder.block.5.layer.0.SelfAttention.k.weight False\n",
            "decoder.block.5.layer.0.SelfAttention.v.weight False\n",
            "decoder.block.5.layer.0.SelfAttention.o.weight False\n",
            "decoder.block.5.layer.0.layer_norm.weight False\n",
            "decoder.block.5.layer.1.EncDecAttention.q.weight False\n",
            "decoder.block.5.layer.1.EncDecAttention.k.weight False\n",
            "decoder.block.5.layer.1.EncDecAttention.v.weight False\n",
            "decoder.block.5.layer.1.EncDecAttention.o.weight False\n",
            "decoder.block.5.layer.1.layer_norm.weight False\n",
            "decoder.block.5.layer.2.DenseReluDense.wi_0.weight False\n",
            "decoder.block.5.layer.2.DenseReluDense.wi_1.weight False\n",
            "decoder.block.5.layer.2.DenseReluDense.wo.weight False\n",
            "decoder.block.5.layer.2.layer_norm.weight False\n",
            "decoder.block.6.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.6.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.6.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.6.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.6.layer.0.layer_norm.weight True\n",
            "decoder.block.6.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.6.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.6.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.6.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.6.layer.1.layer_norm.weight True\n",
            "decoder.block.6.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.6.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.6.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.6.layer.2.layer_norm.weight True\n",
            "decoder.block.7.layer.0.SelfAttention.q.weight True\n",
            "decoder.block.7.layer.0.SelfAttention.k.weight True\n",
            "decoder.block.7.layer.0.SelfAttention.v.weight True\n",
            "decoder.block.7.layer.0.SelfAttention.o.weight True\n",
            "decoder.block.7.layer.0.layer_norm.weight True\n",
            "decoder.block.7.layer.1.EncDecAttention.q.weight True\n",
            "decoder.block.7.layer.1.EncDecAttention.k.weight True\n",
            "decoder.block.7.layer.1.EncDecAttention.v.weight True\n",
            "decoder.block.7.layer.1.EncDecAttention.o.weight True\n",
            "decoder.block.7.layer.1.layer_norm.weight True\n",
            "decoder.block.7.layer.2.DenseReluDense.wi_0.weight True\n",
            "decoder.block.7.layer.2.DenseReluDense.wi_1.weight True\n",
            "decoder.block.7.layer.2.DenseReluDense.wo.weight True\n",
            "decoder.block.7.layer.2.layer_norm.weight True\n",
            "decoder.final_layer_norm.weight True\n",
            "lm_head.weight True\n",
            "\n",
            "Exporting the data to Excel file\n",
            "Conversion complete. Check datasets/hebrew_text_aug_30.xlsx\n",
            "Making the sets smaller due to low available memory\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/375 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb93d83fdd3743ae8047025305d527d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-c5f6c7ae7241>:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask']}\n",
            "<ipython-input-38-c5f6c7ae7241>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx])\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# from datasets import Dataset\n",
        "# from create_augmentations import *\n",
        "# from datasets import load_from_disk\n",
        "# import os\n",
        "# import torch.nn as nn\n",
        "# from torch.utils.data import DataLoader, TensorDataset\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from transformers import BertForSequenceClassification\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from transformers import BertTokenizer, TrainingArguments, Trainer, BatchEncoding, TrainerCallback\n",
        "# from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "# import torch\n",
        "# from transformer_prepare_data import *\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "from tqdm.auto import tqdm\n",
        "import evaluate\n",
        "\n",
        "# ---------- HYPERPARAMETERS -----------\n",
        "# -------------------------------------->\n",
        "BATCH_SIZE = 4\n",
        "num_epochs = 3\n",
        "# <--------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Load the saved datasets\n",
        "model, tokenizer, text_tensor_train_ds, text_tensor_test_ds = get_model_and_data()\n",
        "# text_tensor_train_ds = torch.load('datasets/tokenized/text_tensor_train_ds.pt')\n",
        "# text_tensor_test_ds = torch.load('datasets/tokenized/text_tensor_test_ds.pt')\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
        "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
        "    labels = torch.stack([item['labels'] for item in batch])\n",
        "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(text_tensor_train_ds, shuffle=True, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(text_tensor_test_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'saved_model')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "f67f2c851f3c458e93fec2d3e1c28f6c",
            "3bfc1fdaa0cb49ee87ea70df2e133349",
            "a3de55870a57496a8e0f4f02aa164de2",
            "ecf7d71e877e4f06bbb50e32243a2005",
            "e3d7ac35bbd14b0da6a17fc0a7f6098d",
            "b9128d69f41c4c01a8626d124d88bd31",
            "36072db4e68a445fab877d01686c148c",
            "096a9b2bf5164810bd8d273fd4cf5991",
            "c6caa598a92949e0930e6fbee7a65524",
            "6825d6fd1a844cb5afa3d564a6819918",
            "c4a19291d9004276ac9b76417e86776d"
          ]
        },
        "id": "gWZFD2lz1qrv",
        "outputId": "c0794d5a-143c-47de-89fe-6d59330e9dd8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f67f2c851f3c458e93fec2d3e1c28f6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-c5f6c7ae7241>:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask']}\n",
            "<ipython-input-38-c5f6c7ae7241>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: {'accuracy': 0.10911701363962671}\n"
          ]
        }
      ],
      "source": [
        "num_testing_steps = len(test_dataloader)\n",
        "progress_bar_test = tqdm(range(num_testing_steps))\n",
        "\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "model.eval()\n",
        "for batch in test_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    # metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    # Flatten predictions and references\n",
        "    predictions = predictions.view(-1)\n",
        "    references = batch[\"labels\"].view(-1)\n",
        "\n",
        "    # Filter out padding tokens (if applicable)\n",
        "    mask = references != tokenizer.pad_token_id\n",
        "    predictions = predictions[mask]\n",
        "    references = references[mask]\n",
        "\n",
        "    metric.add_batch(predictions=predictions, references=references)\n",
        "    progress_bar_test.update(1)\n",
        "\n",
        "\n",
        "# Compute the final accuracy\n",
        "final_score = metric.compute()\n",
        "print(\"Accuracy:\", final_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "# from transformer_prepare_data import *\n",
        "\n",
        "# model, tokenizer = get_model_and_data()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "# Sample data for inference\n",
        "new_data = [\"זה טקסט לדוגמא עם שגיעה\", \"עוד תקסט לטיקון\", \"sanity check\"]\n",
        "new_data_tokenized = tokenizer(\n",
        "    new_data, max_length=128, padding='max_length', truncation=True, return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Move data to device\n",
        "input_ids = new_data_tokenized['input_ids'].to(device)\n",
        "attention_mask = new_data_tokenized['attention_mask'].to(device)\n",
        "print(\"Tokenized Input IDs:\", input_ids)\n",
        "print(\"Attention Mask:\", attention_mask)\n",
        "\n",
        "# model.load_state_dict(torch.load('spellcheck_model/saved_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=128,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "\n",
        "predictions = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_ids]\n",
        "print(\"Predictions:\")\n",
        "for i, pred in enumerate(predictions):\n",
        "    print(f\"Input: {new_data[i]}\")\n",
        "    print(f\"Output: {pred}\")\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaqaYub7fKde",
        "outputId": "f0e649dd-8ca6-41b9-9bea-bbb422700abc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Input IDs: tensor([[  2615,    259,  86918,   1808,    667,  39736,   2088,    259,   1533,\n",
            "          83407,  15152,      1,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0],\n",
            "        [   259,   5421,  13650,  18176,    259, 175009, 117881,      1,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0],\n",
            "        [ 57901,    276,   4245,      1,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0]], device='cuda:0')\n",
            "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
            "Predictions:\n",
            "Input: זה טקסט לדוגמא עם שגיעה\n",
            "Output: <extra_id_0>\n",
            "\n",
            "Input: עוד תקסט לטיקון\n",
            "Output: <extra_id_0>\n",
            "\n",
            "Input: sanity check\n",
            "Output: <extra_id_0>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_ids]\n",
        "input = \"שגיאה\"\n",
        "input_encoded = tokenizer.encode(input)\n",
        "input_decoded = tokenizer.decode(input_encoded, skip_special_tokens=True)\n",
        "\n",
        "print(f'input: {input}')\n",
        "print(f'input_encoded: {input_encoded}')\n",
        "print(f'input_decoded: {input_decoded}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HWq6LxsgeSA",
        "outputId": "5abc9fa1-dce7-4261-ab55-d89c27660e80"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: שגיאה\n",
            "input_encoded: [83407, 49491, 1]\n",
            "input_decoded: שגיאה\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb93d83fdd3743ae8047025305d527d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da0be24e821344be84e88159a889ff00",
              "IPY_MODEL_ae76200212d046b4875faf77c161a4a1",
              "IPY_MODEL_ad242f16c8ce4b24b43984f96dd956d2"
            ],
            "layout": "IPY_MODEL_825eca40e75e4e108c2dd46553b4c706"
          }
        },
        "da0be24e821344be84e88159a889ff00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f23530a3c534ae2ae9e52c481ce320f",
            "placeholder": "​",
            "style": "IPY_MODEL_6afb6f1dd6b2485a8f0321d475a197d8",
            "value": "100%"
          }
        },
        "ae76200212d046b4875faf77c161a4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4235ebc3193841738b5137eeeecc0a8f",
            "max": 375,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2597571a875437392135d070bc8bba9",
            "value": 375
          }
        },
        "ad242f16c8ce4b24b43984f96dd956d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b490acd58f64dd08a765b5128014f96",
            "placeholder": "​",
            "style": "IPY_MODEL_7431704876d44438a157e91aef9f3d83",
            "value": " 375/375 [01:51&lt;00:00,  3.47it/s]"
          }
        },
        "825eca40e75e4e108c2dd46553b4c706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f23530a3c534ae2ae9e52c481ce320f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6afb6f1dd6b2485a8f0321d475a197d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4235ebc3193841738b5137eeeecc0a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2597571a875437392135d070bc8bba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b490acd58f64dd08a765b5128014f96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7431704876d44438a157e91aef9f3d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f67f2c851f3c458e93fec2d3e1c28f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bfc1fdaa0cb49ee87ea70df2e133349",
              "IPY_MODEL_a3de55870a57496a8e0f4f02aa164de2",
              "IPY_MODEL_ecf7d71e877e4f06bbb50e32243a2005"
            ],
            "layout": "IPY_MODEL_e3d7ac35bbd14b0da6a17fc0a7f6098d"
          }
        },
        "3bfc1fdaa0cb49ee87ea70df2e133349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9128d69f41c4c01a8626d124d88bd31",
            "placeholder": "​",
            "style": "IPY_MODEL_36072db4e68a445fab877d01686c148c",
            "value": "100%"
          }
        },
        "a3de55870a57496a8e0f4f02aa164de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_096a9b2bf5164810bd8d273fd4cf5991",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6caa598a92949e0930e6fbee7a65524",
            "value": 25
          }
        },
        "ecf7d71e877e4f06bbb50e32243a2005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6825d6fd1a844cb5afa3d564a6819918",
            "placeholder": "​",
            "style": "IPY_MODEL_c4a19291d9004276ac9b76417e86776d",
            "value": " 25/25 [00:14&lt;00:00, 12.71it/s]"
          }
        },
        "e3d7ac35bbd14b0da6a17fc0a7f6098d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9128d69f41c4c01a8626d124d88bd31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36072db4e68a445fab877d01686c148c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "096a9b2bf5164810bd8d273fd4cf5991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6caa598a92949e0930e6fbee7a65524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6825d6fd1a844cb5afa3d564a6819918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4a19291d9004276ac9b76417e86776d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}